---
title: "Introduction: Nebius AI Studio API"
description: "Example section for showcasing API endpoints"
---

<Note>
  Nebius AI Studio offers an [OpenAI-compatible API](https://studio.nebius.com/api-reference) for inference and fine-tuning.
</Note>

Here are examples of Python, JavaScript SDK and cURL command that makes an API request from your terminal:

```python
import os
from openai import OpenAI

client = OpenAI(
    base_url="https://api.studio.nebius.com/v1/",
    api_key=os.environ.get("NEBIUS_API_KEY"),
)

completion = client.chat.completions.create(
    model="meta-llama/Meta-Llama-3.1-70B-Instruct",
    messages=[
        {
            "role": "user",
            "content": """Hello!"""
        }
    ],
    temperature=0.6
)

print(completion.to_json())
```

## Authentication

To authenticate, include your _API key_ (e.g., `ABC123...`) in the `Authorization` header, as shown below:

```
Authorization: Bearer ABC123...
```

<Warning>
  Keep your keys private; do not share or expose them in client-side code. If a key is compromised, Nebius AI Studio can automatically revoke it
</Warning>

To get an API key:

1. In Nebius AI Studio, go to the  [API keys](https://studio.nebius.com/settings/api-keys) section.
2. Click  **Create API key**.
3. Enter the key name and then click **Create**.
4. Save the displayed API key. You cannot open it later in Nebius AI Studio.

<Tip>
  In the [Nebius AI Studio inference playground](https://studio.nebius.com/playground), you can view your model setup and chat as code that makes API requests, and use this code in your applications. For more details, see [View code](https://docs.nebius.com/studio/inference/playground#view-code).
</Tip>

<Tip>
  You can use [integrations with third-party instruments](https://docs.nebius.com/studio/inference/integrations) instead of the API.
</Tip>